{"cells":[{"cell_type":"markdown","metadata":{},"source":["# SIIM-ISIC Melanoma Classification SoSe24"]},{"cell_type":"markdown","metadata":{},"source":["Der Folgende Block lädt relevante Libraries, die für dieses Projekt benötigt werden. Besondere sind: \n","\n","**ThreadPoolExecutor**\n","\n","- Multithreaden von rechenschweren Prozessen\n","- Beschleunigen von Ladeaufgaben\n","\n","\n","**tqdm** \n","\n","- Anzeigen von Ladebalken. \n","- Weiteres Feedback, wenn ein Prozess beendet wird\n","\n","\n","----\n","<span style=\"color:grey\">\n","\n","\n","**Kommentar:**\n","\n","Es können Artefakte in Form von importierten Libraries geben, die nicht weiter ausgeführt werden.\n","</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T07:27:43.666135Z","iopub.status.busy":"2024-06-12T07:27:43.665821Z","iopub.status.idle":"2024-06-12T07:27:59.750104Z","shell.execute_reply":"2024-06-12T07:27:59.749255Z","shell.execute_reply.started":"2024-06-12T07:27:43.666110Z"},"trusted":true},"outputs":[],"source":["import os\n","import datetime\n","import numpy as np\n","import pandas as pd\n","import warnings\n","from tqdm import tqdm\n","from concurrent.futures import ThreadPoolExecutor\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator  # type: ignore\n","from tensorflow.keras import models, layers, optimizers  # type: ignore\n","from tensorflow.keras.models import load_model  # type: ignore\n","from tensorflow.keras.callbacks import EarlyStopping # type: ignore\n","\n","warnings.filterwarnings('ignore')\n","\n","datetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")"]},{"cell_type":"markdown","metadata":{},"source":["# Laden der Bilder und dazugehörigen CSV Dateien. \n","Der folgende Block lädt Bilder und CSV Daten. Diese werden multithreaded, um die Ladezeiten um etwa das x-Fache der verfügbaren Prozessorkerne zu verkürzen.\n","\n","Bilder werden in 128x128 mit Farbe in den RAM geladen, zusätzlich werden die **Namen** und **target** Labels aus der csv-Datei extrahiert und mit den Bildern synchronisiert.\n","\n","Im letzten Schritt werden die Trainingsbilder in Trainings- und Validierungssätzen aufgeteilt. Hierbei werden 20% der Trainingsdaten zu Validierungsdaten allokiert."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T18:58:29.824430Z","iopub.status.busy":"2024-06-11T18:58:29.823516Z","iopub.status.idle":"2024-06-11T19:40:08.760763Z","shell.execute_reply":"2024-06-11T19:40:08.759756Z","shell.execute_reply.started":"2024-06-11T18:58:29.824396Z"},"trusted":true},"outputs":[],"source":["path_data_train = '/kaggle/input/siim-isic-melanoma-classification/train.csv'\n","path_image_train = '/kaggle/input/siim-isic-melanoma-classification/jpeg/train'\n","\n","# Bilder und .csv Dateien laden\n","def load_image(image_path, target_size=(128, 128)):\n","    image = Image.open(image_path).convert('RGB')\n","    image = image.resize(target_size)\n","    return np.array(image)\n","\n","def load_data(csv_file, image_dir, max_images=None, target_size=(128, 128), num_workers=None):\n","    data = pd.read_csv(csv_file)\n","    if max_images is not None:\n","        data = data.head(max_images)\n","\n","    # Bildname und target extrahieren\n","    image_names = data['image_name'].values\n","    targets = data['target'].values\n","\n","    images = []\n","    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n","        futures = []\n","        for image_name in image_names:\n","            image_path = os.path.join(image_dir, image_name + '.jpg')\n","            futures.append(executor.submit(load_image, image_path, target_size))\n","\n","        for future in tqdm(futures, desc=\"Lade Bilder\", total=len(futures)):\n","            images.append(future.result())\n","\n","    return np.array(images), np.array(targets), image_names\n","\n","num_workers = os.cpu_count() or 1   # Setze Threads auf alle erkannten Kerne, ansonsten 1\n","\n","# Laden der Trainingsdaten: Bildname, Bild, target\n","train_images, train_targets, train_image_names = load_data(path_data_train, path_image_train, max_images=None, num_workers=num_workers)\n","\n","# Aufteilen der Trainingsdaten in Trainings- und Validierungssätze\n","train_images, val_images, train_targets, val_targets, train_image_names, val_image_names = train_test_split(train_images, \n","                                                                                                            train_targets, \n","                                                                                                            train_image_names, \n","                                                                                                            test_size=0.2,\n","                                                                                                            random_state=42, \n","                                                                                                            stratify=train_targets)\n","\n","# Verteilung der Labels anzeigen\n","print(\"Verteilung der Trainingslabels:\", np.bincount(train_targets))\n","print(\"Verteilung der Validierungslabels:\", np.bincount(val_targets))\n","\n","datetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")"]},{"cell_type":"markdown","metadata":{},"source":["# Datenaugmentierung von Trainings- und Validierungsdaten\n","Der folgende Block verändert die Verteilung der Trainings- und Validierungsdaten von einer Ungleichheit von '98% zu 2%' zu einer ausgewogeneren Verteilung von '50% zu 50%'. Dies wird durchgeführt, um zu verhindern, dass das Modell dazu neigt, überrepräsentierte Klassen, wie Nullen, zu bevorzugen.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T20:05:07.264168Z","iopub.status.busy":"2024-06-11T20:05:07.263544Z","iopub.status.idle":"2024-06-11T20:06:59.552136Z","shell.execute_reply":"2024-06-11T20:06:59.551095Z","shell.execute_reply.started":"2024-06-11T20:05:07.264135Z"},"trusted":true},"outputs":[],"source":["# Parameter zur Datenaugemntierung festlegen\n","datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","def augment_class_images(class_images, augment_size, generator):\n","    augmented_images = []\n","    for i in tqdm(range(augment_size), desc=\"Augmentiere Bilder\"):\n","        augmented_image = generator.random_transform(class_images[i % len(class_images)])\n","        augmented_images.append(augmented_image)\n","    return np.array(augmented_images)\n","\n","# Bösartige Bilder ermitteln\n","train_minority_class_images = train_images[train_targets == 1]\n","val_minority_class_images = val_images[val_targets == 1]\n","\n","# Augmentationsgröße auf eine Verteilung von 50-50 einstellen\n","train_augment_size = len(train_images[train_targets == 0]) - len(train_minority_class_images)\n","val_augment_size = len(val_images[val_targets == 0]) - len(val_minority_class_images)\n","\n","# Trainings- und Validierungsdaten augmentieren\n","train_augmented_images = augment_class_images(train_minority_class_images, train_augment_size, datagen)\n","train_augmented_targets = np.ones(train_augment_size)\n","val_augmented_images = augment_class_images(val_minority_class_images, val_augment_size, datagen)\n","val_augmented_targets = np.ones(val_augment_size)\n","\n","# Kombinieren der augmentierten Bilder mit den ursprünglichen Daten\n","train_images_balanced = np.concatenate((train_images, train_augmented_images), axis=0)\n","train_targets_balanced = np.concatenate((train_targets, train_augmented_targets), axis=0)\n","val_images_balanced = np.concatenate((val_images, val_augmented_images), axis=0)\n","val_targets_balanced = np.concatenate((val_targets, val_augmented_targets), axis=0)\n","\n","# Mischen der Daten\n","def shuffle_data(images, targets):\n","    indices = np.arange(images.shape[0])\n","    np.random.shuffle(indices)\n","    return images[indices], targets[indices]\n","\n","train_images_balanced, train_targets_balanced = shuffle_data(train_images_balanced, train_targets_balanced)\n","val_images_balanced, val_targets_balanced = shuffle_data(val_images_balanced, val_targets_balanced)\n","\n","train_targets_balanced = train_targets_balanced.astype(int)\n","val_targets_balanced = val_targets_balanced.astype(int)\n","\n","# Verteilung der Labels nach der Augmentation anzeigen\n","print(\"Verteilung der Trainingslabels nach der Augmentation:\", np.bincount(train_targets_balanced))\n","print(\"Verteilung der Validierungslabels nach der Augmentation:\", np.bincount(val_targets_balanced))\n","\n","datetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")"]},{"cell_type":"markdown","metadata":{},"source":["# Erstellen eines CNN Models\n","Der folgende Block definiert ein CNN (Convolutional Neural Network). Mit einem Input von 128x128 Pixeln und 3 Farbkanälen und setzt sich aus drei Convolutional und drei MaxPooling Schichten zusammen. \n","\n","Die Conv2D Schichten starten bei 32 und verdoppeln sich pro Ebene bis 256. \n","\n","MaxPooling wird zwischen die Conv Schichten geschaltet, um die räumliche Größe auf die wichtigsten Pixel zu halbieren.\n","\n","Flatten transformiert die 3 Dimensionale Matrix in eine 1 Dimensionale, um diese an die folgende Dense Schicht verbinden zu können.\n","\n","Dropout deaktiviert 30% zufälliger Neuronen, um Overfitting zu vermeiden.\n","\n","Die letzte Schicht beschreibt die Ausgabe Schicht und gibt nur binäre Werte wieder.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T20:07:03.149758Z","iopub.status.busy":"2024-06-11T20:07:03.149091Z","iopub.status.idle":"2024-06-11T20:07:03.937229Z","shell.execute_reply":"2024-06-11T20:07:03.936378Z","shell.execute_reply.started":"2024-06-11T20:07:03.149722Z"},"trusted":true},"outputs":[],"source":["model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(256, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(512, activation='relu'),\n","    layers.Dropout(0.3),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# Kompilieren und trainieren des Models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T20:07:07.993410Z","iopub.status.busy":"2024-06-11T20:07:07.993011Z","iopub.status.idle":"2024-06-11T20:14:36.877841Z","shell.execute_reply":"2024-06-11T20:14:36.876885Z","shell.execute_reply.started":"2024-06-11T20:07:07.993371Z"},"trusted":true},"outputs":[],"source":["model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Callback\n","early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n","\n","# Model trainieren\n","history = model.fit(train_images_balanced, \n","                    train_targets_balanced, \n","                    batch_size=32,\n","                    epochs=100, \n","                    validation_data=(val_images_balanced, val_targets_balanced))\n","\n","datetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Model speichern"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T20:15:16.561115Z","iopub.status.busy":"2024-06-11T20:15:16.560353Z","iopub.status.idle":"2024-06-11T20:15:16.822049Z","shell.execute_reply":"2024-06-11T20:15:16.821177Z","shell.execute_reply.started":"2024-06-11T20:15:16.561085Z"},"trusted":true},"outputs":[],"source":["model.save(\"/kaggle/working/modelfunktioniert.h5\")\n","datetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T20:22:06.083592Z","iopub.status.busy":"2024-06-11T20:22:06.083200Z","iopub.status.idle":"2024-06-11T20:22:06.306126Z","shell.execute_reply":"2024-06-11T20:22:06.304990Z","shell.execute_reply.started":"2024-06-11T20:22:06.083564Z"},"trusted":true},"outputs":[],"source":["import gc\n","\n","del train_images\n","# del train_targets\n","del val_images\n","# del val_targets\n","\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Visualisierung der Ergebnisse"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T20:22:13.396613Z","iopub.status.busy":"2024-06-11T20:22:13.395998Z","iopub.status.idle":"2024-06-11T20:22:13.919742Z","shell.execute_reply":"2024-06-11T20:22:13.918855Z","shell.execute_reply.started":"2024-06-11T20:22:13.396580Z"},"trusted":true},"outputs":[],"source":["# Visualisierung der Trainings- und Validierungsverluste\n","plt.plot(history.history['loss'], label='train_loss')\n","plt.plot(history.history['val_loss'], label='val_loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.ylim(0, max(history.history['loss'] + history.history['val_loss']))\n","plt.legend()\n","plt.show()\n","\n","# Visualisierung der Trainings- und Validierungsgenauigkeit\n","plt.plot(history.history['accuracy'], label='train_accuracy')\n","plt.plot(history.history['val_accuracy'], label='val_accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.ylim(0, 1)\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Die Konfusionsmatrix zeigt hohe Werte in TP und TN an, was bedeutet, dass das Modell richtig funktioniert"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T20:22:16.164253Z","iopub.status.busy":"2024-06-11T20:22:16.163897Z","iopub.status.idle":"2024-06-11T20:22:16.453934Z","shell.execute_reply":"2024-06-11T20:22:16.452998Z","shell.execute_reply.started":"2024-06-11T20:22:16.164223Z"},"trusted":true},"outputs":[],"source":["# Vorhersagen auf den augmentierten Validierungsdaten\n","val_predictions = (model.predict(val_images_balanced) > 0.5).astype(\"int32\")\n","\n","# Berechnung der Genauigkeit\n","accuracy = accuracy_score(val_targets_balanced, val_predictions)\n","print(f\"Genauigkeit: {accuracy:.2f}\")\n","\n","# Confusion Matrix berechnen\n","conf_matrix = confusion_matrix(val_targets_balanced, val_predictions)\n","\n","# Berechnung von TP, TN, FP und FN\n","TP = conf_matrix[1, 1]\n","TN = conf_matrix[0, 0]\n","FP = conf_matrix[0, 1]\n","FN = conf_matrix[1, 0]\n","\n","# Plot der Confusion Matrix mit Werten\n","plt.figure(figsize=(8, 6))\n","plt.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n","plt.title('Konfusionsmatrix')\n","plt.colorbar()\n","tick_marks = np.arange(2)\n","plt.xticks(tick_marks, ['Negativ', 'Positiv'])\n","plt.yticks(tick_marks, ['Negativ', 'Positiv'])\n","plt.xlabel('Wahre Werte')\n","plt.ylabel('Vorhersage')\n","\n","# Anzeigen von TP, TN, FP und FN\n","plt.text(0, 0, f\"True Negatives (TN): {TN}\", horizontalalignment='center', verticalalignment='center', color='black')\n","plt.text(1, 1, f\"True Positives (TP): {TP}\", horizontalalignment='center', verticalalignment='center', color='black')\n","plt.text(0, 1, f\"False Positives (FP): {FP}\", horizontalalignment='center', verticalalignment='center', color='black')\n","plt.text(1, 0, f\"False Negatives (FN): {FN}\", horizontalalignment='center', verticalalignment='center', color='black')\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Vorbereitung für die Submission in Kaggle\n","Die Testbilder werden geladen, die Namen aus den Bildpfaden extrahiert und in einer Datei submission.csv unter image_name mit den entsprechenden Targets des Modells gespeichert.\n","\n","| image_name | target |\n","| ----------- | ----------- |\n","|ISIC_XXXXXXX|0|\n","|ISIC_XXXXXXX|0|\n","|ISIC_XXXXXXX|1|\n","|ISIC_XXXXXXX|0|\n","|ISIC_XXXXXXX|0|"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T07:28:00.966708Z","iopub.status.busy":"2024-06-12T07:28:00.966126Z","iopub.status.idle":"2024-06-12T07:39:56.784590Z","shell.execute_reply":"2024-06-12T07:39:56.783602Z","shell.execute_reply.started":"2024-06-12T07:28:00.966679Z"},"trusted":true},"outputs":[],"source":["path_image_test = '/kaggle/input/siim-isic-melanoma-classification/jpeg/test'\n","# path_model = '/kaggle/input/model1/tensorflow1/model_abgabe_97_prozent/1/modelfunktioniert.h5' # Vorerstelltes Modell\n","path_model = '/kaggle/working/modelfunktioniert.h5' # Neuerstelltes Modell, für submission\n","\n","# Funktion zum Laden von Bildern\n","def load_image(image_path, target_size=(128, 128)):\n","    image = Image.open(image_path).convert('RGB')\n","    image = image.resize(target_size)\n","    return np.array(image)\n","\n","# Modell laden\n","model = load_model(path_model)\n","\n","# Testbilder laden\n","def load_test_images(image_dir, target_size=(128, 128), num_workers=None):\n","    image_names = os.listdir(image_dir)\n","    images = []\n","\n","    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n","        futures = []\n","        for image_name in image_names:\n","            image_path = os.path.join(image_dir, image_name)\n","            futures.append(executor.submit(load_image, image_path, target_size))\n","\n","        for future in tqdm(futures, desc=\"Lade Testbilder\", total=len(futures)):\n","            images.append(future.result())\n","\n","    return np.array(images), image_names\n","\n","# Anzahl der Prozesse oder Threads einstellen\n","num_workers = os.cpu_count() or 1   # Alle verfügbaren Kerne, die das System erkennt, ansonsten 1\n","\n","# Laden der Testbilder\n","test_images, test_image_names = load_test_images(path_image_test, num_workers=num_workers)\n","\n","datetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T07:44:39.340443Z","iopub.status.busy":"2024-06-12T07:44:39.339803Z","iopub.status.idle":"2024-06-12T07:44:41.953031Z","shell.execute_reply":"2024-06-12T07:44:41.952109Z","shell.execute_reply.started":"2024-06-12T07:44:39.340399Z"},"trusted":true},"outputs":[],"source":["# Vorhersagen auf den Testbildern\n","test_predictions = (model.predict(test_images) > 0.5).astype(\"int32\")\n","\n","# Entfernen der \".jpg\"-Erweiterung von den Bildnamen\n","test_image_names = [os.path.splitext(name)[0] for name in test_image_names]\n","\n","# Ergebnisse in eine DataFrame speichern\n","results = pd.DataFrame({'image_name': test_image_names, 'target': test_predictions.flatten()})\n","\n","# Speichern der Ergebnisse in eine CSV-Datei\n","output_path = '/kaggle/working/submission.csv'\n","results.to_csv(output_path, index=False)\n","\n","datetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")"]},{"cell_type":"markdown","metadata":{},"source":["## Überprüfen, wie die Testdaten verteilt sind und ob diese Korrekt gespeichert wurden"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T07:45:46.580687Z","iopub.status.busy":"2024-06-12T07:45:46.580190Z","iopub.status.idle":"2024-06-12T07:45:46.625254Z","shell.execute_reply":"2024-06-12T07:45:46.624281Z","shell.execute_reply.started":"2024-06-12T07:45:46.580653Z"},"trusted":true},"outputs":[],"source":["submission_df = pd.read_csv(output_path)\n","\n","print(submission_df.head())\n","\n","counts = submission_df['target'].value_counts()\n","\n","# Ausgabe der Ergebnisse\n","print(f\"Anzahl der 0 in den Vorhersagen: {counts.get(0, 0)}\")\n","print(f\"Anzahl der 1 in den Vorhersagen: {counts.get(1, 1)}\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":1222630,"sourceId":20270,"sourceType":"competition"},{"isSourceIdPinned":true,"modelInstanceId":53742,"sourceId":64447,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
