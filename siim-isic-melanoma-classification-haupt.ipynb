{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":20270,"databundleVersionId":1222630,"sourceType":"competition"},{"sourceId":35223,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":29657}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SIIM-ISIC Melanoma Classification SoSe24","metadata":{}},{"cell_type":"markdown","source":"Folgender Block lädt willkürliche Libraries, weil ich keine Ahnung habe was ich mache, aber dafür gibt es einen coolen Timer.","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['KERAS_BACKEND'] = 'tensorflow'\n\nimport datetime\nimport numpy as np\nimport pandas as pd # Einlesen von CSV Dateien\nimport warnings\nfrom tqdm import tqdm # Ladebalken\nfrom tqdm.contrib.concurrent import process_map\nfrom concurrent.futures import ThreadPoolExecutor # Multiprocessing beschleunigt das Laden um etwa das 6 Fache\nfrom PIL import Image\nfrom IPython.display import display\nimport matplotlib.pyplot as plt # Anzeigen von Bildern\nimport plotly.express as px # Interaktive Diagramme\nfrom keras.models import load_model\nfrom sklearn.metrics import roc_curve, precision_recall_curve, f1_score\n\nfrom sklearn.model_selection import train_test_split # Aufteilen in Trainings- und Validierungssa#tze\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder # Kodierung der Labels\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras import models, layers, optimizers\n\nwarnings.filterwarnings('ignore')\n\ndatetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-23T12:46:57.383452Z","iopub.execute_input":"2024-04-23T12:46:57.384299Z","iopub.status.idle":"2024-04-23T12:47:11.761020Z","shell.execute_reply.started":"2024-04-23T12:46:57.384264Z","shell.execute_reply":"2024-04-23T12:47:11.760022Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-23 12:47:00.724503: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-23 12:47:00.724619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-23 12:47:00.857540: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'Fertiggestellt um 12:47:11 den 04/23/24'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Visualisierung der absoluten Häufigkeit der Merkmalsausprägungen","metadata":{}},{"cell_type":"code","source":"# CSV-Datei lesen\ndata = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\n\n# Merkmalsausprägungen und Verteilung extrahieren\nsex_counts = data['sex'].value_counts()\nage_counts = data['age_approx'].value_counts()\nanatom_counts = data['anatom_site_general_challenge'].value_counts()\ntarget_counts = data['target'].value_counts()\n\n# Daten in DataFrame umwandeln und Spalten bennenen\nsex_df = pd.DataFrame({'Abs. H.': sex_counts.values}, index=sex_counts.index)\nage_df = pd.DataFrame({'Abs. H.': age_counts.values}, index=age_counts.index)\nanatom_df = pd.DataFrame({'Abs. H.': anatom_counts.values}, index=anatom_counts.index)\ntarget_df = pd.DataFrame({'Abs. H.': target_counts.values}, index=target_counts.index)\n\n# Kuchendiagramme erstellen\nfig_sex = px.pie(sex_df, names=sex_df.index, values='Abs. H.', title='Geschlecht', \n                  labels={'Abs. H. ': 'Anzahl '})\nfig_age = px.pie(age_df, names=age_df.index, values='Abs. H.', title='Gesch. Alter', \n                 labels={'Abs. H. ': 'Anzahl '})\nfig_anatom = px.pie(anatom_df, names=anatom_df.index, values='Abs. H.', title='Anatom. Stelle', \n                    labels={'Abs. H. ': 'Anzahl '})\nfig_target = px.pie(target_df, names=target_df.index, values='Abs. H.', title='Target', \n                    labels={'Abs. H. ': 'Anzahl '})\n\n# Diagramme anzeigen\nfig_sex.show()\nfig_age.show()\nfig_anatom.show()\nfig_target.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Laden der Bilder und dazugehörigen CSV Dateien. \nDer folgende Block lädt Bilder und CSV Daten. Diese werden multiprocessed, um die Arbeitszeit zu vervierfachen i.e. anstelle der sonstigen >5min/1000 Bilder in <2m/1000 Bilder","metadata":{}},{"cell_type":"code","source":"path_data_train = '/kaggle/input/siim-isic-melanoma-classification/train.csv'\npath_image_train = '/kaggle/input/siim-isic-melanoma-classification/jpeg/train'\n\n# Funktion zum Laden von Bildern\ndef load_image(image_path, target_size=(256, 256)):\n    image = Image.open(image_path).convert('RGB')\n    image = image.resize(target_size)\n    return np.array(image)\n\ndef load_data(csv_file, image_dir, max_images=None, target_size=(256, 256), num_workers=None):\n    data = pd.read_csv(csv_file)\n    if max_images is not None:\n        data = data.head(max_images)\n\n    # Auswählen der relevanten Spalten für Kodierung\n    data_for_encoding = data[['sex', 'age_approx', 'anatom_site_general_challenge', 'target']]\n\n    # Kodieren der kategorialen Variablen in numerische Werte\n    label_encoders = {}\n    for column in ['sex', 'age_approx', 'anatom_site_general_challenge', 'target']:\n        label_encoders[column] = LabelEncoder()\n        data_for_encoding[column] = label_encoders[column].fit_transform(data_for_encoding[column])\n\n    # Extrahieren der Bildnamen\n    image_names = data['image_name'].values\n\n    images = []\n    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n        futures = []\n        for image_name in image_names:\n            image_path = os.path.join(image_dir, image_name + '.jpg')\n            futures.append(executor.submit(load_image, image_path, target_size))\n\n        for future in tqdm(futures, desc=\"Lade Bilder\", total=len(futures)):\n            images.append(future.result())\n\n    labels = data_for_encoding.values\n\n    return np.array(images), np.array(labels), image_names, label_encoders\n\n\n# Anzahl der Prozesse oder Threads einstellen\nnum_workers = os.cpu_count() or 1\n\n# Laden der Trainingsdaten mit kodierten Labels\ntrain_images, train_labels, train_image_names, label_encoders = load_data(path_data_train, path_image_train, max_images=None)\n\n\n# Aufteilen der Trainingsdaten in Trainings- und Validierungssätze\ntrain_images, val_images, train_labels, val_labels, train_image_names, val_image_names = train_test_split(train_images, \n                                                                                                          train_labels, \n                                                                                                          train_image_names, \n                                                                                                          test_size=0.2, \n                                                                                                          random_state=42)\n\n\ndatetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T12:47:36.043544Z","iopub.execute_input":"2024-04-23T12:47:36.044516Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Lade Bilder:   5%|▍         | 1496/33126 [01:51<24:07, 21.85it/s]  ","output_type":"stream"}]},{"cell_type":"markdown","source":"# Anzeigen eines Melanombildes zur überprüfung, dass die Daten korrekt geladen wurden\nUm die geladenen Bilder und Labels auf Synchronität zu prüfen, müssen manuell die Bildnamen, die Bilder","metadata":{}},{"cell_type":"code","source":"for i, label in enumerate(train_labels):\n    if label[-1] == 1:\n        print(i, '\\n')\n        print(f\"Das Bild '{train_image_names[i]}' ist ein Melanom.\")\n        plt.figure()\n        plt.imshow(train_images[i])\n        plt.show()\n        break # Nur 1. Wenn break auskommentiert wird, dann alle Melanome","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model definieren","metadata":{}},{"cell_type":"code","source":"# Definieren des Modells\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),\n    layers.Dense(1, activation='sigmoid')  # Ausgabeschicht mit einem Neuron und Sigmoid-Aktivierungsfunktion\n])\n\n# Kompilieren des Modells\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',  # Binäre Kreuzentropie als Verlustfunktion für binäre Klassifikation\n              metrics=['accuracy'])\n\n\n\ndatetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Anpassen des Modells an die Trainingsdaten\nhistory = model.fit(train_images, train_labels[:, -1], epochs=10, batch_size=16, validation_data=(val_images, val_labels[:, -1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/working/model2.h5\")\ndatetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualisierung der Ergebnisse","metadata":{}},{"cell_type":"code","source":"# Visualisierung der Trainings- und Validierungsverluste\nplt.plot(history.history['loss'], label='train_loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim(0, max(history.history['loss'] + history.history['val_loss']))  # Setze die y-Achsenbegrenzung von 0 bis zum maximalen Verlustwert\nplt.legend()\nplt.show()\n\n# Visualisierung der Trainings- und Validierungsgenauigkeit\nplt.plot(history.history['accuracy'], label='train_accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim(0, 1)  # Setze die y-Achsenbegrenzung von 0 bis 1 für die Genauigkeit\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testbilder","metadata":{}},{"cell_type":"code","source":"# Pfade für Testdaten und CSV-Datei definieren\npath_data_test = '/kaggle/input/siim-isic-melanoma-classification/test.csv'\npath_image_test = '/kaggle/input/siim-isic-melanoma-classification/jpeg/test'\n\ndef load_test_data(csv_file, image_dir, max_images=None, target_size=(256, 256), num_workers=None):\n    data = pd.read_csv(csv_file)\n    if max_images is not None:\n        data = data.head(max_images)\n\n    # Kodieren der kategorialen Variablen in numerische Werte mit den vorher trainierten Label Encodern\n    for column in ['sex', 'age_approx', 'anatom_site_general_challenge']:\n        if column in label_encoders:\n            data[column] = label_encoders[column].transform(data[column])\n\n    # Extrahieren der Bildnamen\n    image_names = data['image_name'].values\n\n    return image_names, data\n\ndef load_test_images(image_names, image_dir, target_size=(256, 256), num_workers=None):\n    images = []\n    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n        futures = []\n        for image_name in image_names:\n            image_path = os.path.join(image_dir, image_name + '.jpg')\n            futures.append(executor.submit(load_image, image_path, target_size))\n\n        for future in tqdm(futures, desc=\"Lade Testbilder\", total=len(futures)):\n            images.append(future.result())\n\n    return np.array(images)\n\n\n# Laden der Testdaten\ntest_image_names, test_data = load_test_data(path_data_test, path_image_test)\n\n# Laden der Testbilder\ntest_images = load_test_images(test_image_names, path_image_test)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T12:47:27.287798Z","iopub.execute_input":"2024-04-23T12:47:27.288860Z","iopub.status.idle":"2024-04-23T12:47:28.065313Z","shell.execute_reply.started":"2024-04-23T12:47:27.288826Z","shell.execute_reply":"2024-04-23T12:47:28.064016Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(images)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Laden der Testdaten\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m test_image_names, test_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_test_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_data_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_image_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Laden der Testbilder\u001b[39;00m\n\u001b[1;32m     38\u001b[0m test_images \u001b[38;5;241m=\u001b[39m load_test_images(test_image_names, path_image_test)\n","Cell \u001b[0;32mIn[2], line 12\u001b[0m, in \u001b[0;36mload_test_data\u001b[0;34m(csv_file, image_dir, max_images, target_size, num_workers)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Kodieren der kategorialen Variablen in numerische Werte mit den vorher trainierten Label Encodern\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_approx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manatom_site_general_challenge\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlabel_encoders\u001b[49m:\n\u001b[1;32m     13\u001b[0m         data[column] \u001b[38;5;241m=\u001b[39m label_encoders[column]\u001b[38;5;241m.\u001b[39mtransform(data[column])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Extrahieren der Bildnamen\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'label_encoders' is not defined"],"ename":"NameError","evalue":"name 'label_encoders' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import random\n\n# Anzahl der zufällig ausgewählten Bilder, die angezeigt werden sollen\nnum_images_to_display = 5\n\n# Zufällige Indizes auswählen\nrandom_indices = random.sample(range(len(test_images)), num_images_to_display)\n\n# Bilder mit zufälligen Indizes anzeigen\nfor idx in random_indices:\n    image = test_images[idx]\n    image_name = test_image_names[idx]\n    age = test_data.iloc[idx]['age_approx']\n    sex = test_data.iloc[idx]['sex']\n    \n    plt.imshow(image)\n    plt.title(f\"Image Name: {image_name}\\nAge: {age}, Sex: {sex}\")\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testtestestestesteststestsettteststestestsetsetestsetsetsetsesetset\nprint(\"Anzahl der Trainingsdaten:\", len(train_images))\nprint(\"Anzahl der Validierungsdaten:\", len(val_images))\nprint('\\n')\nprint(\"Anzahl der geladenen Bilder:\", len(train_images))\nprint(\"Anzahl der geladenen Labels:\", len(train_labels))\nprint('\\n')\nprint(\"Train Labels:\", train_labels)\n#print(\"Train Bildernamen:\", image_names_train)\n\ndatetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column, encoder in label_encoders.items():\n    print(f\"Kodierung für '{column}':\")\n    print(encoder.classes_)\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modell laden\n\nmodel_load = load_model('/kaggle/input/model-1/tensorflow1/model1/1/model1.h5')\n\n# Vorhersagen für Testdaten machen\npredictions = model_load.predict(test_images)\n\n# Ergebnisse in eine DataFrame speichern, einschließlich der Bildnamen\nresults_df = pd.DataFrame({'image_name': test_image_names, 'target': predictions.flatten()})\n\n# Ergebnisse in eine CSV-Datei speichern\nresults_df.to_csv('/kaggle/working/submission.csv', index=False)\n\ndatetime.datetime.now().strftime(\"Fertiggestellt um %X den %x\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef display_test_images(test_images, test_image_names, num_images=5):\n    plt.figure(figsize=(15, 7))\n    for i in range(num_images):\n        plt.subplot(1, num_images, i+1)\n        plt.imshow(test_images[i])\n        plt.title(test_image_names[i])\n        plt.axis('off')\n    plt.show()\n\n# Anzahl der Testbilder, die angezeigt werden sollen\nnum_display_images = 5\n\n# Testbilder und Namen anzeigen\ndisplay_test_images(test_images, test_image_names, num_display_images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Berechnung der Vorhersagen des Modells\npredictions = model_load.predict(test_images)\n\n# Berechnung der ROC-Kurve\nfpr, tpr, thresholds_roc = roc_curve(test_labels, predictions)\n\n# Berechnung der Precision-Recall-Kurve\nprecision, recall, thresholds_pr = precision_recall_curve(test_labels, predictions)\n\n# Berechnung des F1-Scores für verschiedene Schwellenwerte\nf1_scores = [f1_score(test_labels, (predictions > threshold)) for threshold in thresholds_roc]\n\n# Finden des optimalen Schwellenwerts basierend auf dem F1-Score\noptimal_threshold_index = np.argmax(f1_scores)\noptimal_threshold = thresholds_roc[optimal_threshold_index]\n\n# Visualisierung der ROC-Kurve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, label='ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Visualisierung der Precision-Recall-Kurve\nplt.figure(figsize=(8, 6))\nplt.plot(recall, precision, label='Precision-Recall curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Visualisierung des F1-Scores über verschiedene Schwellenwerte\nplt.figure(figsize=(8, 6))\nplt.plot(thresholds_roc, f1_scores, label='F1 Score')\nplt.axvline(x=optimal_threshold, color='r', linestyle='--', label='Optimal Threshold')\nplt.xlabel('Threshold')\nplt.ylabel('F1 Score')\nplt.title('F1 Score vs. Threshold')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nprint(\"Optimaler Schwellenwert basierend auf dem F1-Score:\", optimal_threshold)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}